#!/usr/bin/env python3
"""
Streamlit dashboard for GolfSim results exploration and optimization guidance.

Features:
- Top-of-page controls (no left sidebar) for all key configuration levers
- Dynamic KPIs, distributions, and staffing recommendations
- Pulls from combined and aggregated CSVs already generated by batch + optimization runs
"""

from __future__ import annotations

import math
from typing import Dict, List, Optional, Tuple
import os
import sys
import subprocess
from pathlib import Path
import time
import webbrowser

import numpy as np
import pandas as pd
import streamlit as st


# ---------------------------- Page setup ----------------------------
st.set_page_config(
    page_title="GolfSim Optimization Dashboard",
    layout="wide",
    initial_sidebar_state="collapsed",
)


# ---------------------------- Data loading ----------------------------
@st.cache_data(show_spinner=False)
def load_data() -> Tuple[pd.DataFrame, pd.DataFrame, Optional[pd.DataFrame]]:
    combined = pd.read_csv("combined_simulation_results.csv")
    aggregated = pd.read_csv("aggregated_simulation_results.csv")
    # Optimization results are optional (only present if optimization ran)
    try:
        opt_results = pd.read_csv("outputs/optimization_20250814_182612/optimization_results.csv")
    except Exception:
        opt_results = None
    return combined, aggregated, opt_results


def _safe_float(value: object, default: float = 0.0) -> float:
    try:
        if value is None or (isinstance(value, str) and value.strip() == ""):
            return default
        return float(value)
    except Exception:
        return default


def _map_prevention_label(value: object) -> str:
    """Normalize prevention variant to canonical labels: none, front1_3, front1_5, front1_6."""
    if value is None:
        return "none"
    s = str(value).strip().lower()
    if s in ("", "nan", "none", "no", "0"):
        return "none"
    # numeric forms
    try:
        n = int(float(s))
        if n <= 0:
            return "none"
        if n == 3:
            return "front1_3"
        if n == 5:
            return "front1_5"
        if n == 6:
            return "front1_6"
    except Exception:
        pass
    # labeled forms
    s = s.replace(" ", "").replace("to", "_").replace("..", "_").replace("-", "_")
    if "front1_3" in s:
        return "front1_3"
    if "front1_5" in s:
        return "front1_5"
    if "front1_6" in s:
        return "front1_6"
    return "none"


def _add_prevention_label_columns(df: pd.DataFrame) -> pd.DataFrame:
    if "prevent_front_upto_hole" in df.columns:
        df = df.copy()
        df["prevention_label"] = df["prevent_front_upto_hole"].apply(_map_prevention_label)
        return df
    # If not present, synthesize as none
    df = df.copy()
    df["prevention_label"] = "none"
    return df


combined_df, aggregated_df, opt_results_df = load_data()
combined_df = _add_prevention_label_columns(combined_df)
aggregated_df = _add_prevention_label_columns(aggregated_df)


# ---------------------------- Controls (top of page) ----------------------------
st.title("GolfSim Simulation & Optimization Dashboard")

with st.container():
    # Core dimensions (delivery-only, simplified)
    # Scenario display in Proper Case without underscores
    scenario_key_options = sorted([s for s in combined_df["scenario"].dropna().unique()])
    key_to_label = {k: k.replace("_", " ").title() for k in scenario_key_options}
    label_to_key = {v: k for k, v in key_to_label.items()}
    scenario_labels = [key_to_label[k] for k in scenario_key_options]
    default_label = key_to_label.get("busy_weekend", scenario_labels[0] if scenario_labels else "Busy Weekend")

    col1, col2, col3 = st.columns(3)
    with col1:
        scenario_label_sel = st.selectbox("Scenario", options=scenario_labels, index=scenario_labels.index(default_label))
        scenario_sel = label_to_key.get(scenario_label_sel, scenario_key_options[0])

    # Fixed on-call threshold internally
    ON_CALL_THRESHOLD = 20.0

    # Prepare options source filtered by scenario and runner mode
    df_for_opts = combined_df[(combined_df["scenario"] == scenario_sel) & (combined_df["mode"] == "runner")]

    # Runner-related controls
    runner_cols = st.columns(4)
    with runner_cols[0]:
        # Limit slider to 1-4 as requested
        num_runners_sel = st.slider("Num runners", min_value=1, max_value=4, value=3, step=1)
    with runner_cols[1]:
        # Front prevention
        prev_opts = ["none", "front1_3", "front1_5", "front1_6"]
        prevention_sel = st.selectbox("Front prevention", options=prev_opts, index=0)
    with runner_cols[2]:
        # Use total orders per day, back into closest delivery_order_prob present in data
        # Determine reasonable slider bounds from data
        totals = pd.to_numeric(df_for_opts["total_orders"], errors="coerce").dropna()
        if totals.empty:
            min_total, max_total = 0, 200
        else:
            min_total, max_total = int(max(0, totals.min() // 1)), int(min(500, totals.max() // 1))
            if min_total >= max_total:
                min_total, max_total = 0, int(max(100, min_total + 50))
        total_orders_target = st.slider("Total orders (day)", min_value=min_total, max_value=max_total, value=min(60, max_total), step=1)
    with runner_cols[3]:
        show_opt_targets = st.checkbox("Show optimization recommendations (if available)", value=True)


# ---------------------------- Filtering ----------------------------
def compute_selected_delivery_prob(
    df_runner: pd.DataFrame,
    scenario_key: str,
    prevention_label: str,
    target_total_orders: int,
) -> Optional[str]:
    """Derive the closest delivery_order_prob for the target total orders using per-run data."""
    scope = df_runner[(df_runner["scenario"] == scenario_key) & (df_runner["mode"] == "runner")].copy()
    if scope.empty or "delivery_order_prob" not in scope.columns:
        return None
    scope = _add_prevention_label_columns(scope)
    # If total_orders is unavailable (e.g., some sources), fallback to mode of probs
    if "total_orders" not in scope.columns:
        try:
            return str(scope["delivery_order_prob"].mode().iloc[0])
        except Exception:
            return None
    grp = (
        scope.groupby(["delivery_order_prob", "prevention_label"], dropna=True)["total_orders"].mean().reset_index()
    )
    if grp.empty:
        try:
            return str(scope["delivery_order_prob"].mode().iloc[0])
        except Exception:
            return None
    cand = grp[grp["prevention_label"] == prevention_label].copy()
    if cand.empty:
        cand = grp.copy()
    cand.loc[:, "diff"] = (cand["total_orders"] - float(target_total_orders)).abs()
    cand = cand.sort_values("diff")
    try:
        return str(cand.iloc[0]["delivery_order_prob"])
    except Exception:
        return None


def apply_filters(df: pd.DataFrame, selected_prob: Optional[str]) -> pd.DataFrame:
    out = df.copy()
    # Scenario and delivery-only
    out = out[out["scenario"] == scenario_sel]
    if "mode" in out.columns:
        out = out[out["mode"] == "runner"]
    out = _add_prevention_label_columns(out)
    # Apply selected delivery probability if present
    if selected_prob is not None and "delivery_order_prob" in out.columns:
        out = out[out["delivery_order_prob"].astype(str) == str(selected_prob)]
    # Prevention and runner count
    out = out[out["prevention_label"] == prevention_sel]
    if "num_runners" in out.columns:
        out = out[out["num_runners"] == int(num_runners_sel)]
    return out


def _safe_float_series(s: pd.Series) -> pd.Series:
    return pd.to_numeric(s, errors="coerce").fillna(np.nan)


selected_prob = compute_selected_delivery_prob(
    combined_df,
    scenario_key=scenario_sel,
    prevention_label=prevention_sel,
    target_total_orders=int(total_orders_target),
)

filtered_combined = apply_filters(combined_df, selected_prob)
filtered_aggregated = apply_filters(aggregated_df, selected_prob)


# ---------------------------- KPIs and summaries ----------------------------
def summarize_kpis(df: pd.DataFrame) -> Dict[str, Optional[float]]:
    if df.empty:
        return {}

    metrics = {}
    for col in [
        "on_time_rate", "failed_rate", "delivery_cycle_time_p50", "delivery_cycle_time_p90",
        "queue_depth_avg", "queue_wait_avg", "util_driving_pct", "orders_per_runner_hour",
        "total_orders", "total_revenue", "bev_orders_per_cart_hour", "bev_holes_covered_per_hour",
        "bev_total_visibility_events", "order_penetration_rate", "revenue_per_round", "average_order_value",
    ]:
        if col in df.columns:
            series = pd.to_numeric(df[col], errors="coerce")
            if series.notna().any():
                metrics[f"{col}_mean"] = float(series.mean())
                metrics[f"{col}_median"] = float(series.median())
    metrics["n_runs"] = int(len(df))
    return metrics


def staffing_recommendation_from_kpis(kpis: Dict[str, float], threshold_pct: float) -> str:
    if not kpis:
        return "Insufficient Data"
    on_time = kpis.get("on_time_rate_mean", 0.0)
    failed = kpis.get("failed_rate_mean", 1.0)
    util = kpis.get("util_driving_pct_mean", None)
    if util is None:
        return "Insufficient Data"
    if on_time >= 0.95 and failed <= 0.05 and util < threshold_pct:
        return "On-Call Candidate"
    if on_time >= 0.95 and failed <= 0.05 and 20 <= util <= 40:
        return "Optimal Dedicated"
    if on_time >= 0.90 and util > 40:
        return "High Efficiency"
    if on_time < 0.90 or failed > 0.10:
        return "Understaffed"
    return "Standard"


runner_mode_active = True
bev_mode_active = False

kpis = summarize_kpis(filtered_combined)

st.markdown("---")
st.subheader("Results")

if not kpis:
    st.warning("No data for the selected filters. Adjust the controls above.")
else:
    # KPI cards
    kpi_cols = st.columns(6)
    if runner_mode_active:
        kpi_cols[0].metric("On-time rate (mean)", f"{kpis.get('on_time_rate_mean', 0)*100:.1f}%")
        kpi_cols[1].metric("Failed rate (mean)", f"{kpis.get('failed_rate_mean', 0)*100:.1f}%")
        kpi_cols[2].metric("Cycle time p50 (min)", f"{kpis.get('delivery_cycle_time_p50_mean', 0):.1f}")
        kpi_cols[3].metric("Cycle time p90 (min)", f"{kpis.get('delivery_cycle_time_p90_mean', 0):.1f}")
        kpi_cols[4].metric("Driving utilization", f"{kpis.get('util_driving_pct_mean', 0):.1f}%")
        kpi_cols[5].metric("Orders/runner/hr", f"{kpis.get('orders_per_runner_hour_mean', 0):.2f}")

    # Beverage-cart KPIs removed for delivery-only view

    # Staffing recommendation
    rec = staffing_recommendation_from_kpis(kpis, ON_CALL_THRESHOLD)
    st.info(f"Staffing recommendation: {rec}")

    # Table: Filtered runs (delivery-only)
    with st.expander("Filtered runs (combined)", expanded=False):
        df_view = filtered_combined.copy()
        # Scenario label in proper case
        df_view["Scenario"] = df_view["scenario"].apply(lambda x: key_to_label.get(str(x), str(x).replace("_", " ").title()))
        # Front prevention label
        df_view = _add_prevention_label_columns(df_view)
        df_view["Front Prevention"] = df_view["prevention_label"].str.replace("_", " ").str.title()
        # Select and rename columns
        cols_map = {
            "Scenario": "Scenario",
            "num_runners": "Num Runners",
            "total_orders": "Total Orders",
            "on_time_rate": "On-time Rate",
            "failed_rate": "Failed Rate",
            "delivery_cycle_time_p50": "Cycle p50 (min)",
            "delivery_cycle_time_p90": "Cycle p90 (min)",
            "queue_depth_avg": "Queue Depth",
            "queue_wait_avg": "Queue Wait (min)",
            "util_driving_pct": "Driving Util",
            "orders_per_runner_hour": "Orders/Runner/Hr",
            "total_revenue": "Total Revenue",
            "Front Prevention": "Front Prevention",
        }
        ordered_cols = [
            "Scenario", "Num Runners", "Front Prevention", "Total Orders",
            "On-time Rate", "Failed Rate", "Cycle p50 (min)", "Cycle p90 (min)",
            "Queue Depth", "Queue Wait (min)", "Driving Util", "Orders/Runner/Hr", "Total Revenue",
        ]
        present = [c for c in cols_map.keys() if c in df_view.columns or c in df_view]
        df_display = df_view.rename(columns=cols_map)[ordered_cols]
        # Formatting
        styler = df_display.style.format({
            "Total Orders": "{:,.0f}",
            "On-time Rate": "{:.1%}",
            "Failed Rate": "{:.1%}",
            "Cycle p50 (min)": "{:.1f}",
            "Cycle p90 (min)": "{:.1f}",
            "Queue Depth": "{:.2f}",
            "Queue Wait (min)": "{:.1f}",
            "Driving Util": "{:.1f}%",
            "Orders/Runner/Hr": "{:.2f}",
            "Total Revenue": "${:,.2f}",
        })
        st.dataframe(styler, use_container_width=True)

    # Download filtered runs
    st.download_button(
        label="Download filtered runs CSV",
        data=filtered_combined.to_csv(index=False).encode("utf-8"),
        file_name="filtered_runs.csv",
        mime="text/csv",
    )

    # ---------------------------- Map App Integration ----------------------------
    def _select_run_row_for_current_filters(df: pd.DataFrame) -> Optional[pd.Series]:
        c = df.copy()
        # Prefer batch_experiment rows if present
        if "data_source" in c.columns:
            c = c[c["data_source"] == "batch_experiment"]
        # Ensure required identifiers exist
        needed = ["batch_id", "simulation_id"]
        for col in needed:
            if col not in c.columns:
                return None
        c = c[c["batch_id"].notna() & (c["batch_id"].astype(str).str.len() > 0)]
        c = c[c["simulation_id"].notna() & (c["simulation_id"].astype(str).str.len() > 0)]
        if c.empty:
            return None
        # Stable ordering: smallest run_index then seed as tiebreaker
        order_cols = [col for col in ["run_index", "seed"] if col in c.columns]
        if order_cols:
            c = c.sort_values(order_cols)
        return c.iloc[0]

    def _guess_manifest_id(simulation_id: str) -> str:
        base = Path("outputs") / f"replay_{simulation_id}"
        candidates = [
            ("run_01", "coordinates.csv"),
            ("sim_01", "coordinates.csv"),
            ("sim_01", "bev_cart_coordinates.csv"),
        ]
        for folder, fname in candidates:
            path = base / folder / fname
            if path.exists():
                name_wo_ext = Path(fname).stem
                return f"replay_{simulation_id}_{folder}_{name_wo_ext}"
        # Fallback to runner default
        return f"replay_{simulation_id}_run_01_coordinates"

    def _run_replay_and_publish_to_map(batch_id: str, simulation_id: str) -> Tuple[bool, str]:
        # 1) Replay the selected run into outputs/replay_{simulation_id}
        replay_cmd = [
            sys.executable,
            str(Path("scripts") / "sim" / "replay_from_batch.py"),
            "--batch-dir",
            str(Path("outputs") / batch_id),
            "--simulation-id",
            str(simulation_id),
            "--output-dir",
            "outputs",
            "--course-dir",
            "courses/pinetree_country_club",
            "--log-level",
            "INFO",
        ]
        try:
            rc = subprocess.run(replay_cmd, check=False)
            if rc.returncode != 0:
                return False, f"Replay failed (exit {rc.returncode})"
        except Exception as e:
            return False, f"Replay error: {e}"

        # 2) Publish to React app by copying coordinates + writing manifest
        # Compute preferred default simulation id for manifest
        preferred_id = _guess_manifest_id(simulation_id)

        env = os.environ.copy()
        env["SIM_BASE_DIR"] = str(Path("outputs").resolve())
        env["DEFAULT_SIMULATION_ID"] = preferred_id

        try:
            rc2 = subprocess.run(
                [sys.executable, str(Path("my-map-animation") / "run_map_app.py")],
                check=False,
                env=env,
                cwd=str(Path("my-map-animation").resolve()),
            )
            if rc2.returncode != 0:
                return False, f"Map publish failed (exit {rc2.returncode})"
        except Exception as e:
            return False, f"Map publish error: {e}"

        return True, preferred_id

    st.markdown("\n")
    col_btn1, col_btn2 = st.columns([1, 3])
    with col_btn1:
        if st.button("Load into Map App", type="primary"):
            with st.spinner("Replaying and publishing to Map App..."):
                row = _select_run_row_for_current_filters(filtered_combined)
                if row is None:
                    st.error("No matching run with batch metadata found for current filters.")
                else:
                    ok, info = _run_replay_and_publish_to_map(str(row["batch_id"]), str(row["simulation_id"]))
                    if ok:
                        st.success("Map App updated. Open or refresh the React app to see the new simulation.")
                        st.caption(f"Default selection set to: {info}")
                        try:
                            # Attempt to auto-open/refresh the running React app
                            base_url = os.environ.get("MAP_APP_URL", "http://localhost:3000/")
                            cache_buster = f"t={int(time.time())}"
                            sep = "&" if "?" in base_url else "?"
                            webbrowser.open(f"{base_url}{sep}{cache_buster}")
                        except Exception:
                            pass
                    else:
                        st.error(info)

    # Optimization recommendations (if available)
    if show_opt_targets and opt_results_df is not None and runner_mode_active:
        st.markdown("---")
        st.subheader("Optimization-based recommendations")

        # Normalize prevention
        opt_view = opt_results_df.copy()
        opt_view = opt_view[opt_view["scenario"] == scenario_sel]
        # Use current filtered runs to determine selected delivery probability
        if not filtered_combined.empty and "delivery_order_prob" in filtered_combined.columns:
            sel_prob = str(filtered_combined["delivery_order_prob"].astype(str).mode().iloc[0])
            opt_view = opt_view[opt_view["delivery_prob"].astype(str) == sel_prob]
        opt_view = opt_view[opt_view["prevention_variant"].apply(_map_prevention_label) == prevention_sel]

        if opt_view.empty:
            st.caption("No optimization results match current filters.")
        else:
            # Show optimal runners per target
            cols = [
                "scenario", "prevention_variant", "delivery_prob", "target_name", "optimal_runners", "achieved_metric", "optimization_status",
            ]
            st.dataframe(opt_view[cols].sort_values(["scenario", "prevention_variant", "delivery_prob", "target_name"]), use_container_width=True)

            # Suggested runner count summary
            summary = (
                opt_view.groupby(["scenario", "prevention_variant", "delivery_prob"])  # type: ignore
                .agg(optimal_runners_avg=("optimal_runners", "mean"))
                .reset_index()
            )
            st.caption("Average optimal runners across targets (where available)")
            st.dataframe(summary, use_container_width=True)


st.markdown("---")
st.caption("Tip: Use the controls above to explore different configurations. This app intentionally avoids a left sidebar per requirements.")


